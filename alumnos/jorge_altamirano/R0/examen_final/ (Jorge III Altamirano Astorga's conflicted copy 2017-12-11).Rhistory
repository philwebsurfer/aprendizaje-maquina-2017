camino <- numeric(pasos) # vector que guardará las simulaciones
camino[1] <- 90 # valor inicial
rechazo = 0
for (j in 2:pasos){
camino[j] <- caminaAleat(camino[j - 1], sd_prop = 20)
rechazo <- rechazo + 1 * (camino[j] == camino[j - 1])
}
rp20 <- rechazo / pasos
caminata20 <- data.frame(pasos = 1:pasos, theta = camino)
g3 <- ggplot(caminata20[1:2000, ], aes(x = pasos, y = theta)) +
geom_point(size = 0.8) +
geom_path(alpha = 0.3) +
ggtitle("N(0,20)")
grid.arrange(g1,g2,g3,ncol=3)
prior <- function(mu = 100, tau = 10){
mu <- mu
tau <- tau
function(theta){
dnorm(theta, mu, tau)
}
}
mu <- 150
tau <- 15
mi_prior <- prior(mu, tau)
# mu
# tau
# mi_prior(5)
# S: sum x_i, S2: sum x_i^2, N: número obs., sigma: desviación estándar (conocida)
S <- 13000
S2 <- 1700000
N <- 100
sigma <- 20
likeNorm <- function(S, S2, N, sigma = sigma){
# quitamos constantes
sigma2 <-  sigma ^ 2
function(theta){
exp(-1 / (2 * sigma2) * (S2 - 2 * theta * S +
N * theta ^ 2))
}
}
mi_like <- likeNorm(S = S, S2 = S2, N = N, sigma = sigma)
# mi_like(130)
postRelProb <- function(theta){
mi_like(theta) * mi_prior(theta)
}
caminaAleat <- function(theta, sd_prop = .2){ # theta: valor actual
salto_prop <- rnorm(n = 1, sd = sd_prop) # salto propuesto
theta_prop <- theta + salto_prop # theta propuesta
u <- runif(1)
p_move = min(postRelProb(theta_prop) / postRelProb(theta), 1) # prob mover
if(p_move  > u){
return(theta_prop) # aceptar valor propuesto
}
else{
return(theta) # rechazar
}
}
### 0.2
# Generamos la caminata aleatoria
pasos <- 6000
camino <- numeric(pasos) # vector que guardará las simulaciones
camino[1] <- 90 # valor inicial
rechazo = 0
for (j in 2:pasos){
camino[j] <- caminaAleat(camino[j - 1])
rechazo <- rechazo + 1 * (camino[j] == camino[j - 1])
}
rp0.2 <- rechazo / pasos
caminata0.2 <- data.frame(pasos = 1:pasos, theta = camino)
g1 <- ggplot(caminata0.2[1:2000, ], aes(x = pasos, y = theta)) +
geom_point(size = 0.8) +
geom_path(alpha = 0.3) +
ggtitle("N(0, 0.2)")
#### 5
# Generamos la caminata aleatoria
pasos <- 6000
camino <- numeric(pasos) # vector que guardará las simulaciones
camino[1] <- 90 # valor inicial
rechazo = 0
for (j in 2:pasos){
camino[j] <- caminaAleat(camino[j - 1], sd_prop = 5)
rechazo <- rechazo + 1 * (camino[j] == camino[j - 1])
}
rp5 <- rechazo / pasos
caminata5 <- data.frame(pasos = 1:pasos, theta = camino)
g2 <- ggplot(caminata5[1:2000, ], aes(x = pasos, y = theta)) +
geom_point(size = 0.8) +
geom_path(alpha = 0.3) +
ggtitle("N(0, 5)")
#### 20
# Generamos la caminata aleatoria
pasos <- 6000
camino <- numeric(pasos) # vector que guardará las simulaciones
camino[1] <- 90 # valor inicial
rechazo = 0
for (j in 2:pasos){
camino[j] <- caminaAleat(camino[j - 1], sd_prop = 20)
rechazo <- rechazo + 1 * (camino[j] == camino[j - 1])
}
rp20 <- rechazo / pasos
caminata20 <- data.frame(pasos = 1:pasos, theta = camino)
g3 <- ggplot(caminata20[1:2000, ], aes(x = pasos, y = theta)) +
geom_point(size = 0.8) +
geom_path(alpha = 0.3) +
ggtitle("N(0,20)")
grid.arrange(g1,g2,g3,ncol=3)
rabbits
rabbits
summary(rabbits)
summary(rabbits$tumor %>% as.factor())
rabbits
summary(rabbits)
summary(rabbits$tumor %>% as.factor())
modelo_conejos.txt <-
'
model{
for(i in 1 : N) {
y[i] ~ dbern(p[expr[i]])
}
for(j in 1 : nExp) {
p[j] ~ dbeta(a, b)
}
a <- mu*k
b <- (1-mu)*k
mu ~ dbeta(1, 1)
k ~ dgamma(1, 0.1)
}
'
cat(modelo_conejos.txt, file = 'modelo_conejos.txt')
jags_fit_conejos <- jags(
model.file = "modelo_conejos.txt",    # modelo de JAGS
# inits = jags.inits,   # valores iniciales
data = list(y = rabbits$tumor, expr = rabbits$experiment,
nExp = length(unique(rabbits$experiment)),
N = length(rabbits$tumor)),    # lista con los datos
parameters.to.save = c("mu", "k", "p"),  # parámetros por guardar
n.chains = 3,   # número de cadenas
n.iter = 6000,    # número de pasos
n.burnin = 1000   # calentamiento de la cadena
)
#jags_fit_conejos
k_pasos <- jags_fit_conejos$BUGSoutput$sims.matrix[,2]
k_pasos <- data.frame(k = k_pasos)
mu_pasos <- jags_fit_conejos$BUGSoutput$sims.matrix[,3]
mu_pasos <- data.frame(mu = mu_pasos)
ggplot(k_pasos, aes(x = k)) +
geom_histogram(aes(y = ..density..))
k_pasos <- jags_fit_conejos$BUGSoutput$sims.matrix[,2]
k_pasos <- data.frame(k = k_pasos)
mu_pasos <- jags_fit_conejos$BUGSoutput$sims.matrix[,3]
mu_pasos <- data.frame(mu = mu_pasos)
ggplot(k_pasos, aes(x = k)) +
geom_histogram(aes(y = ..density..)) +
ggtitle("Conejos distribución posterior")
k_pasos <- jags_fit_conejos$BUGSoutput$sims.matrix[,2]
k_pasos <- data.frame(k = k_pasos)
mu_pasos <- jags_fit_conejos$BUGSoutput$sims.matrix[,3]
mu_pasos <- data.frame(mu = mu_pasos)
g1 <- ggplot(k_pasos, aes(x = k)) +
geom_histogram(aes(y = ..density..)) +
ggtitle("Posterior de mu")
g2 <- ggplot(mu_pasos, aes(x = mu)) +
geom_histogram(aes(y = ..density..)) +
ggtitle("Posterior de kappa")
grid.arrange(g1,g2,ncol=2)
p <- jags_fit_conejos$BUGSoutput$sims.matrix[,-c(1:3)] %>% data.frame
med_p_52 <- colMeans(p)
q <- gather(p,key = p)
ggplot(q, aes(p, value)) + geom_boxplot()
modelo_conejos54.txt <-
'
model{
for(i in 1 : N) {
y[i] ~ dbern(p[expr[i]])
}
for(j in 1 : nExp) {
p[j] ~ dbeta(a, b)
}
a <- mu*k
b <- (1-mu)*k
mu ~ dbeta(10, 10)
k ~ dgamma(.51, 00.1)
}
'
cat(modelo_conejos54.txt, file = 'modelo_conejos54.txt')
modelo_conejos54.txt <-
'
model{
for(i in 1 : N) {
y[i] ~ dbern(p[expr[i]])
}
for(j in 1 : nExp) {
p[j] ~ dbeta(a, b)
}
a <- mu*k
b <- (1-mu)*k
mu ~ dbeta(10, 10)
k ~ dgamma(.51, 00.1)
}
'
cat(modelo_conejos54.txt, file = 'modelo_conejos54.txt')
jags_fit_conejos54 <- jags(
model.file = "modelo_conejos54.txt",    # modelo de JAGS
# inits = jags.inits,   # valores iniciales
data = list(y = rabbits$tumor, expr = rabbits$experiment,
nExp = length(unique(rabbits$experiment)),
N = length(rabbits$tumor)),    # lista con los datos
parameters.to.save = c("mu", "k", "p"),  # parámetros por guardar
n.chains = 3,   # número de cadenas
n.iter = 6000,    # número de pasos
n.burnin = 1000   # calentamiento de la cadena
)
# jags_fit_conejos54
p54 <- jags_fit_conejos54$BUGSoutput$sims.matrix[,-c(1:3)] %>% data.frame
med_p_54 <- colMeans(p54)
q54 <- gather(p54,key = p54)
g1 <- ggplot(q54, aes(p54, value)) +
geom_boxplot() +
ggtitle("")
media_5254 <- data.frame(m_52 = med_p_52, m_54 = med_p_54)
g2 <- ggplot(media_5254, aes(x = m_52, y = m_54)) +
geom_point() +
ggtitle("")
p54 <- jags_fit_conejos54$BUGSoutput$sims.matrix[,-c(1:3)] %>% data.frame
med_p_54 <- colMeans(p54)
q54 <- gather(p54,key = p54)
g1 <- ggplot(q54, aes(p54, value)) +
geom_boxplot() +
ggtitle("")
media_5254 <- data.frame(m_52 = med_p_52, m_54 = med_p_54)
g2 <- ggplot(media_5254, aes(x = m_52, y = m_54)) +
geom_point() +
ggtitle("")
grid.arrange(g1,g2,ncol=2)
library(plyr)
library(tidyverse)
library(jsonlite)
library(glmnet)
library(rpart)
library(rpart.plot)
library(randomForest)
library(doParallel)
registerDoParallel(cores=detectCores()-1)
library(parallelSVM)
set.seed(175904)
train_raw <- fromJSON("data/train.json")
train_raw <- train_raw %>% as.data.frame
train_raw$train <- F
train_raw[sample(nrow(train_raw), nrow(train_raw)*.7, replace = F), 4] <- T
train <- train_raw[train_raw$train == T,1:3]
valid <- train_raw[train_raw$train == F,1:3]
train_2 <- train
valid_2 <- valid
ggplot(train_raw, aes(x=train)) +
geom_histogram(stat="count")
unimportant_words <- "(^a taste of|any|low-fat|low ?salt|all|powder|baby|bertolli|boiled|boiling|bone in|whole|boneless|bottled|sauvignon|california|campbells condensed|canned|chopped|flavored carbonated beverage|cold|condensed|cooked|cooking|cereal|lowfat|frosting|spread|soften|with chives.*|ic peach| of .*|creamed|creamy| mexican.?|crushed|crystal farms|shredded|crystallized|crystal hot|cubed|curly|curlyleaf|jelly|dessert mix|sauce mix|mix|dark|dellallo|deepfried|deep fried|diced|diet|tortilla chips||domino|dried|minced|dry|earth balance|elmlea|^english|evaporated|everglades|extra fine|extra firm|extra large|extra\\s?lean|extra light|extra sharp|extra\\s?virgin|extra wide|^fat|fat\\s?free|fat skimmed|fatfree?|fattrimmed|fine|firm|firmly packed|flat |^flavored|terrine|food|free\\s?range|^french|^fresh| root|^fresno|^fried|^frozen|^fuji|full\\s?fat|gluten\\s?free|s milk |^gold|golden|gourmet|graham|granulated|grassfed|grated|grating|gravenstein|great|greater|style|green|grilled|grill|ground|half|heavy|heinz|hellmanns?|of the woods|herbed |herdez|hidden valley|homemade|^hot |hot smoked|hot spanish|^hungarian|hurst|i cantbelieve? its? not butter|imitation|imperial sugar light brown|instant |^irish|^italian|italianstyle|^japanese |jimmy dean|johnsonville|jose cuervo|jumbo|kikkoman|knorr|knudsen|kraft|mexican style|kraft zesty|slim cut|sun dried|shredded|la victoria|land o lakes|^large|^lean|leftover|leg of|zest|less sodium|lesser|leaves|^light|cook and drain|lipton|liquid |^lite|^long |loosely packed fresh|low fat|lowfat|^low sodium|lower sodium|lowfat|baked|\\sdeli|firm silken|styl|lowsodium|and cheese dinner|madagascar bourbon|extract|mccormick|^medium|uncook|uncooked|merguez|^mexican|minced|mini|mini|mixed|mixture|mizkan|^mms|mrs dash|natural|^nido|non dairy|non fat|non stick|nondairy|nonfat|frozen|nonhydrogenated|nosaltadded|old el paso|old|old\\s?fashioned|cooking spray|flavored|^organic|oscar mayer|other|oven\\s?ready|flavor|flavour|paella|reggiano|peeled|^petite|pillsbury|powdered|prepared|preserv|preserved|progresso|\\sdi\\sparma|pt|pte|puff|puffed|pure|quickcooking|quick|cooking|raw|red|reduced\\sfat|reduced\\ssodium|reduced\\ssugar|reducedfat|reducedsodium|reducedsugar|refrigerated|regular|rich|roasted|roast|roasting|robert mondavi|salt free seasoning|salt free chili powder|salt free cajun creole seasoning|salt free southwest chipotle seasoning|salt free herb seasoning|salt free chili powder|salted|saltines?|saltpeper|san marazano|sargento|links|casings|savoy|seafood|seasoned|seasoning|seedless|self ?ra?ising|shredded|single|simple|skinless|sliced|small|smoked|sodium free|sodium reduced|soft|softened|solid|southern comfort.*|southwest|sparkling|spicy|splenda.*|split|spring water|^strip|superfine|sweetened|taco bell.*|into serving pieces|to\\s+lb|toasted|uncle bens|^uncook|^uncooked|unflavou?red|unsweetened|white|wholesome sweeteners|wholemilk|wide|^wild|^winter|wish\\s?bone|yellow|young|zesty|part ?skim|italian|all ?purpose|puree|juice|aged|tuna in water|liqueur|liquor|^asian|and .*|yoplait|greek|fresh|spray|hot water|warm water|crumbles|freshly|flakes?|unsalt|unsalted|wedges?|plain)(\\s|$)"
popular_words <- function(a){
a <- gsub("(.*)(beans?|lettuce|olives?|tabasco|potato(es)?|cilantro|wheat|shiitake|lemon|chives?|tomato(es)?|cabbage|peanut|yogh?o?urt|rice|onions?|ginger|sesame|jalapeno|stock|bacon|monterey_jack|vinegar|sausages?|mozz?arell?a|monterey_jack|feta|ricotta|dijon|masala|eggs?|coconut_milk|cheddar|dijon|parmesan|sour_(crema|cream)|steak|pork|beef|chicken|oyster|garlic|salt|curry).*", "\\2", a)
}
#limpiar datos de ingredientes
train_2$ingredients <- sapply(1:nrow(train), function(x) {
train[x,3] %>%
unlist %>%
tolower %>%
gsub("\\([^)]*\\)", "", ., perl = T, ignore.case = T) %>%
gsub("[^ a-z]", "", ., perl = T, ignore.case = T) %>%
gsub("^\\s+", " ", ., perl = T, ignore.case = T) %>%
gsub(unimportant_words, " ", ., perl = T, ignore.case = T) %>%
gsub("\\s+", " ", ., perl = T, ignore.case = T) %>%
unique %>%
trimws %>%
gsub("\\s", "_", ., perl = T, ignore.case = T) %>%
popular_words
})
#limpiar los datos de validación
valid_2$ingredients <- sapply(1:nrow(valid), function(x) {
valid[x,3] %>%
unlist %>%
tolower %>%
gsub("\\([^)]*\\)", "", ., perl = T, ignore.case = T) %>%
gsub("[^ a-z]", "", ., perl = T, ignore.case = T) %>%
gsub("^\\s+", " ", ., perl = T, ignore.case = T) %>%
gsub(unimportant_words, " ", ., perl = T, ignore.case = T) %>%
gsub("\\s+", " ", ., perl = T, ignore.case = T) %>%
unique %>%
trimws %>%
gsub("\\s", "_", ., perl = T, ignore.case = T) %>%
popular_words
})
train_2$cuisine <- train_2$cuisine %>% as.factor
valid$cuisine <- valid$cuisine %>% as.factor
ingredients <- train_2$ingredients %>%
unlist
ingredients <- ingredients[which(!grepl(pattern = "^$", x = ingredients))] #%>%
#    unique
ingredients %>% head(n=10)
ingredients_df <- as.data.frame(ingredients, stringsAsFactors = F) %>%
group_by(ingredients)
ingredients_count <- ingredients_df %>%
plyr::count(.) %>%
arrange(freq)
ingredients_count$id <- 1:nrow(ingredients_count)
head(ingredients_count)
tail(ingredients_count)
ingredients_top <- ingredients_count %>%
filter(freq > 150) %>%
arrange(desc(freq)) %>%
select(ingredients)
train_3 <- train_2[,1:2]
valid_3 <- valid_2[,1:2]
#crea las columnas
train_3[, ingredients_top %>% unlist] <- 0
valid_3[, ingredients_top %>% unlist] <- 0
#llena las columnas
for(i in 1:nrow(train_3)){
train_3[i, which(names(train_3) %in% (train_2[i,]$ingredients %>% unlist))] <- 1
}
for(i in 1:nrow(valid_3)){
valid_3[i, which(names(valid_3) %in% (valid_2[i,]$ingredients %>% unlist))] <- 1
}
rm(i)
saveRDS(train_2, "data/train_2.rds")
saveRDS(train_3, "data/train_3.rds")
saveRDS(valid_2, "data/valid_2.rds")
saveRDS(valid_3, "data/valid_3.rds")
# train_2 <- readRDS("data/train_2.rds")
# train_3 <- readRDS("data/train_3.rds")
# valid_2 <- readRDS("data/valid_2.rds")
# valid_3 <- readRDS("data/valid_3.rds")
train_3 %>%
select(id,cuisine,garlic,salt,pepper) %>%
head(n=5)
valid_3 %>%
select(id,cuisine,garlic,salt,pepper) %>%
head(n=5)
ggplot(ingredients_count %>% filter(freq > 100),aes(x=id, y=log(freq)))+geom_line() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
n_ing <- train_2$ingredients
# a_ing <-
train_2$n_ing <- sapply(1:length(n_ing),function(i){length(n_ing[[i]])})
ggplot(train_2 , aes(x=cuisine,y=n_ing)) +
geom_boxplot() +
theme(axis.text.x=element_text(angle=90,hjust=1))
rm(n_ing)
data.frame( Cuisine = unique(train_2$cuisine),
Mean = aggregate(train_2$n_ing, list(train_2$cuisine), mean)[,2],
SD = aggregate(train_2$n_ing, list(train_2$cuisine), sd)[,2],
Min = aggregate(train_2$n_ing, list(train_2$cuisine), min)[,2],
Max = aggregate(train_2$n_ing, list(train_2$cuisine), max)[,2])
ggplot(train_2, aes(n_ing, group = cuisine)) +
geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
scale_y_continuous(labels=scales::percent) +
ylab("relative frequencies") +
facet_wrap(~cuisine)
ggplot((train_2$cuisine %>% plyr::count()), aes(x = reorder(x, -freq), y = freq)) +
geom_bar(stat = "identity") +
xlab("Cuisine") +
ylab("Frecuencias") +
theme(axis.text.x=element_text(angle=90,hjust=1))
# lm <- glmnet(x = train_3[,3:100] %>% as.matrix,
#                 y = train_3$cuisine,
#                 family = "multinomial",
#                 alpha = 1)
# train_3$lm <- predict(arbol_grande, newdata = train_3[,3:210], type="class")
# train_3 %>% mutate(lm_pred = (cuisine == lm)) %>% select(lm_pred) %>% summary
# train_3 %>% select(cuisine, lm)
# valid_3$lm <- predict(lm, newdata = valid_3[,3:210], type="class")
# valid_3 %>% mutate(lm_pred = (cuisine == lm)) %>% select(lm_pred) %>% summary
# valid_3 %>% select(cuisine, lm)
# arbol_grande <- rpart(cuisine ~ ., data= train_3[,-1], cp=0)
# save(arbol_grande, file = "data/arbol.Rdata")
load(file = "data/arbol.Rdata")
prp(prune(arbol_grande, cp=0.03), type=4, extra=1, digits=3)
train_3$arbol <- predict(arbol_grande, newdata = train_3[,3:210], type="class")
train_3 %>% mutate(arbol_pred = (cuisine == arbol)) %>% select(arbol_pred) %>% summary
train_3 %>% select(cuisine, arbol)
# bosque <- foreach(ntree=rep(150, 3), .combine=combine, .multicombine=TRUE,
#               .packages='randomForest') %dopar% {
#     randomForest(cuisine ~ . , data = train_3[,2:210], ntree=ntree)
#               }
# save(bosque, file="data/bosque.Rdata")
load("data/bosque.Rdata")
train_3$bosque <- predict(bosque, newdata = train_3[,3:210], type="class")
train_3 %>% mutate(bosque_pred = (cuisine == bosque)) %>% select(bosque_pred) %>% summary
train_3 %>% select(cuisine, bosque)
valid_3$bosque <- predict(bosque, newdata = valid_3[,3:210], type="class")
valid_3 %>% mutate(bosque_pred = (cuisine == bosque)) %>% select(bosque_pred) %>% summary
valid_3 %>% select(cuisine, bosque)
# set.seed(175904)
# svm <- parallelSVM(cuisine ~ . , data = train_3[,2:210],
#             numberCores = detectCores()-1,
#             samplingSize = 0.2,
#             na.action = na.omit,
#             scale = TRUE)
# save(svm, file = "data/svm.Rdata")
load(file = "data/svm.Rdata")
train_3$svm <- predict(svm, newdata = train_3[,3:210], type="class")
train_3 %>% mutate(svm_pred = (cuisine == svm)) %>% select(svm_pred) %>% summary
train_3 %>% select(cuisine, svm)
valid_3$svm <- predict(svm, newdata = valid_3[,3:210], type="class")
valid_3 %>% mutate(svm_pred = (cuisine == svm)) %>% select(svm_pred) %>% summary
valid_3 %>% select(cuisine, svm)
test_raw <- fromJSON("data/test.json")
test_raw <- test_raw %>% as.data.frame
test <- test_raw
# test_raw$ingredients %>% unlist
test$ingredients <- sapply(1:nrow(test_raw), function(x) {
test[x,2] %>%
unlist %>%
tolower %>%
gsub("\\([^)]*\\)", "", ., perl = T, ignore.case = T) %>%
gsub("[^ a-z]", "", ., perl = T, ignore.case = T) %>%
gsub("^\\s+", " ", ., perl = T, ignore.case = T) %>%
gsub(unimportant_words, " ", ., perl = T, ignore.case = T) %>%
gsub("\\s+", " ", ., perl = T, ignore.case = T) %>%
unique %>%
trimws %>%
gsub("\\s", "_", ., perl = T, ignore.case = T) %>%
popular_words
})
test
test_2 <- test[,1] %>% data_frame(id=.)
#crea las columnas
test_2[, ingredients_top$ingredients] <- 0
#llena las columnas
for(i in 1:nrow(test_2)){
test_2[i, which(names(test_2) %in% (test[i,]$ingredients %>% unlist))] <- 1
}
test_2
test_2$cuisine <- predict(svm, newdata = test_2[,1:209], type="class")
test_2 %>% select(id,cuisine) %>% summary
test_2 %>% select(id, cuisine) %>% write_csv(., "data/svm_submission.csv")
train <- fromJSON("data/train.json")
train <- train %>% as.data.frame
train %>% head(n=4) %>% kable
train %>% head(n=4) %>% kable
library(knitr)
train %>% head(n=4) %>% kable
train$ingredients %>% unlist %>%  tolower %>%unique %>% data.frame(x=.) %>% arrange(x) %>%  head(n=10) %>% kable
saveRDS(ingredients_top, "data/ingredients_top.Rdata")
saveRDS
saveRDS
saveRDS(ingredients_top, "data/ingredients_top.Rdata")
ingredients_top <- readRDS("data/ingredients_top.Rdata")
ggplot(ingredients_count %>% filter(freq > 100),aes(x=id, y=log(freq)))+geom_line() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
ingredients_top <- readRDS("data/ingredients_top.Rdata")
ggplot(ingredients_count,aes(x=id, y=log(freq)))+geom_line() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
ingredients_top <- readRDS("data/ingredients_top.Rdata")
ggplot(ingredients_count,aes(x=id, y=log(freq)))+geom_line() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
saveRDS(ingredients_count, "data/ingredients_count.Rdata")
ingredients_count <- readRDS("data/ingredients_count.Rdata")
ggplot(ingredients_count,aes(x=id, y=log(freq)))+geom_line() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
ingredients_count <- readRDS("data/ingredients_count.Rdata")
train_2 <- readRDS("data/train_2.rds")
g1<-ggplot(ingredients_count,aes(x=id, y=log(freq)))+geom_line() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
g2<-ggplot(train_2, aes(n_ing, group = cuisine)) +
geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
scale_y_continuous(labels=scales::percent) +
ylab("relative frequencies") +
facet_wrap(~cuisine)
gridExtra::grid.arrange(g1,g2,ncol=1)
n_ing <- train_2$ingredients
# a_ing <-
train_2$n_ing <- sapply(1:length(n_ing),function(i){length(n_ing[[i]])})
rm(n_ing)
train_2$n_ing
train_2$n_ing
saveRDS(train_2,"data/train_2.rds")
train_2 <- readRDS("data/train_2.rds")
ingredients_count <- readRDS("data/ingredients_count.Rdata")
train_2 <- readRDS("data/train_2.rds")
g1<-ggplot(ingredients_count,aes(x=id, y=log(freq)))+geom_line() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
g2<-ggplot(train_2, aes(n_ing, group = cuisine)) +
geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
scale_y_continuous(labels=scales::percent) +
ylab("relative frequencies") +
facet_wrap(~cuisine)
gridExtra::grid.arrange(g1,g2,ncol=1)
ggplot(train_2, aes(n_ing, group = cuisine)) +
geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
scale_y_continuous(labels=scales::percent) +
ylab("relative frequencies") +
facet_wrap(~cuisine)
ingredients_count <- readRDS("data/ingredients_count.Rdata")
ingredients_count <- readRDS("data/ingredients_count.Rdata")
ggplot(ingredients_count,aes(x=id, y=log(freq)))+geom_line() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
```{r, echo=FALSE}
ggplot((train_2$cuisine %>% plyr::count()), aes(x = reorder(x, -freq), y = freq)) +
geom_bar(stat = "identity") +
xlab("Cuisine") +
ylab("Frecuencias") +
theme(axis.text.x=element_text(angle=90,hjust=1))
glimpse(train_3)
saveRDS(train_3, "data/train_3.rds")
train_3$svm <- predict(svm, newdata = train_3[,3:210], type="class")
valid_3 %>% mutate(svm_pred = (cuisine == svm)) %>% select(svm_pred) %>% summary
train_3 %>% mutate(svm_pred = (cuisine == svm)) %>% select(svm_pred) %>% summary
train_3 %>% select(cuisine, svm)
valid_3 <- readRDS("data/valid_3.rds")
valid_3 %>% mutate(svm_pred = (cuisine == svm)) %>% select(svm_pred) %>% summary
valid_3
valid_3 %>% glimpse %>% tail
data.frame(c("FALSE", "TRUE"), c(4096, 7837))
data.frame(c("FALSE", "TRUE"), c(4096, 7837))
data.frame(correctos=c("FALSE", "TRUE"), c(4096, 7837))
