---
title: "Tarea 2 - 2017/08/28"
output: html_notebook
---
#Tarea 2 - 2017/08/28

#Introducción

Datos descargados de `https://archive.ics.uci.edu/ml/machine-learning-databases/housing/`

Leyendo el archivo

```{r}
library(readr)
library(dplyr)
library(ggplot2)
library(purrr)
library(knitr)
set.seed(175904)
housing = read.csv("housing.data", header = FALSE, sep = "", col.names = c("CRIM", "ZN", "INDUS", "CHAS", "NOX", "RM", "AGE", "DIS", "RAD", "TAX", "PTRATIO", "B", "LSTAT", "MEDV"))
housing$id = seq.int(nrow(housing))
housing_l = sample_n(housing, 400) #learning df
housing_t = housing[!(housing$id %in% housing_l$id),] #test df
#housing = housing[,!(names(housing) %in% c("id"))]
#housing_l = housing_l[(names(housing))]
#alternativo test_t
#housing_t = anti_join(housing, housing_l, by = "id") 
#housing_t = housing_t[(names(housing))]
```

## Descripción de la muestra

Esta es la descripción de las variables de la muestra de prueba. Por ejemplo: rango, media, mediana, por ejemplo.

### Para los datos de entrenamiento

```{r}
summary(housing_l)
```


### Para los datos de prueba

```{r}
summary(housing_t)
```

## MEDV 

Observando todas las variables respecto a MEDV...
```{r}
pairs(MEDV~AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT, data=housing_l)
```
```{r}
pairs(MEDV~CRIM + ZN + INDUS + CHAS + NOX + RM, data=housing_l)
```

#### Modelo lineal general

```{r}
model1 = lm(MEDV ~ AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT + CRIM + ZN + INDUS + CHAS + NOX + RM, data = housing_l)
summary(model1)
```


Se observa que las variables más relevante imho son:
* LSTAT: % de la gente de clase baja
* RM: Habitaciones en la propiedad
<!-- * B: Proporción de gente de color -->
<!-- * DIS: distancia a alguno de los 5 centros de trabajo de Boston -->
<!-- * NOX: concentración de NOx (contaminación) -->
<!-- * PTRATIO: Proporción alumno-docente -->
<!-- * CHAS: Índice de accesibilidad a autopistas -->


Ingresándolas a un modelo lineal...

```{r}
model1 = lm(MEDV ~ LSTAT + RM, data = housing_l)
summary(model1)
```


## MEDV: RSS (Residual Sum of Squares)

```{r}
rss_calc <- function(datos){
  y <- datos$MEDV
  x1 <- datos$LSTAT
  x2 <- datos$RM
  fun_out <- function(beta){
    y_hat <- beta[1] + beta[2]*x1 + beta[3]*x2
    e <- (y - y_hat)
    rss <- sum(e^2)
    0.5*rss
  }
  fun_out
}

rss <- rss_calc(housing_l)
beta <- c(33.95616, -0.92478, 5.34982)
rss(beta)
```

###Prueba 

Usando los valores de regresión lineal ahora en los valores de prueba
```{r}
loess1 = loess(MEDV ~ LSTAT + B, data = housing_l, span=1)
loess5 = loess(MEDV ~ LSTAT + B, data = housing_l, span=5)
loess20 = loess(MEDV ~ LSTAT + B, data = housing_l, span=20)
loess50 = loess(MEDV ~ LSTAT + B, data = housing_l, span=50)
ggplot(housing_t, aes(x = LSTAT, y = MEDV, color = RM)) + geom_point() +
  geom_abline(slope=beta[2], intercept=beta[1], color="blue", size=1.1) + 
  geom_smooth(se =FALSE, colour='green', size=1.1, span=1, method='loess') +
  geom_smooth(se =FALSE, colour='brown', size=1.1, span=5, method='loess') +
  geom_smooth(se =FALSE, colour='purple', size=1.1, span=20, method='loess') +
  geom_smooth(se =FALSE, colour='pink', size=1.1, span=50, method='loess')
```

```{r}
res_opt <- optim(c(0,0, 0), rss, method = 'BFGS')
beta_hat <- res_opt$par
beta_hat
```
```{r}
res_opt$convergence
```

```{r}
ggplot(housing_t, aes(x=LSTAT, y=MEDV, color=B)) + geom_point() +
  scale_color_gradient(low = "yellow", high = "red") +
  geom_abline(slope=beta[2], intercept=beta[1], color="blue", size=1.1) +
  geom_abline(slope=beta_hat[2], intercept=beta_hat[1], color="red", size=3.1) +
  geom_smooth(se =FALSE, colour='green', size=1.1, span=1, method='loess', data = housing_l, show.legend = TRUE) +
  geom_smooth(se =FALSE, colour='brown', size=1.1, span=5, method='loess', data = housing_l) +
  geom_smooth(se =FALSE, colour='purple', size=1.1, span=20, method='loess', data = housing_l) +
  geom_smooth(se =FALSE, colour='pink', size=1.1, span=50, method='loess', data = housing_l)
```

## Errores de Entrenamiento y Prueba

```{r}
error_f <- function(df){
  function(mod){
    # if(typeof(mod) == "closure") {
    #   beta2 = c(-3.5288493, -0.6035707,  5.3498213)
    #   rss2 = rss_calc(df)
    #   preds = rss2(beta2)
    # } else {
    # }
    preds <- predict(mod, newdata = df)
    round(sqrt(mean((preds-df$MEDV)^2)))
  }
}

error_l <- error_f(housing_l)
error_t <- error_f(housing_t)
df_mods <- data.frame(name = c('y=mx+b', 'loess 1', 'loess 5', 'loess 20', 'loess 50'))
df_mods$model = list(model1, loess1, loess5, loess20, loess50)
df_mods <- df_mods %>% mutate(error_l = map_dbl(model, error_l))
df_mods <- df_mods %>% mutate(error_t = map_dbl(model, error_t))
df_mods
```

#### Error de Prueba

